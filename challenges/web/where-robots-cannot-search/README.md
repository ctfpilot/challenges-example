# Where robots cannot search

A challenge based on the notion of robots.txt, and how it should never be used to hide sensitive information.

The challenge name refers to robots (web scrapers) that are not allowed to search for certain files on a website, therefore giving the hint that the flag is located in a file that is disallowed in the robots.txt file.

## Challenge

A website is given, which contains a robots.txt file, in this file one or more directories and files are disallowed.  
However, one of them is called `flag.txt`, which contains the flag.

## Story

To fit the Brunnerne story, the website is a simple landing page for the `Brunnerne company`.
